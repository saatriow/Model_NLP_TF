# -*- coding: utf-8 -*-
"""ModelNLPTF_Sat.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QUL77HfbjVQ6Icz3kOop3_Q9wJkKm-xn

### Nama : Muhammad Priambodo Satrio Wibowo

### Email : satriow110702@gmail.com

sumber: https://www.kaggle.com/datasets/lazrus/headlines-5000
"""

# Commented out IPython magic to ensure Python compatibility.

import pandas as pd
import seaborn as sns
import io
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Flatten, Dropout, Dense

sns.set()
# %matplotlib inline

df = pd.read_csv('https://raw.githubusercontent.com/saatriow/Model_NLP_TF/main/Headlines_5000.csv')

df.head

df.shape

df.isnull().values.any()

plt.figure(figsize=(10,5))
sns.countplot(df['category'])
plt.xticks(rotation=45)
plt.show()

review = pd.get_dummies(df['category'])
df2 = pd.concat([df, review], axis=1)
df2 = df2.drop('category', axis=1)
df2.head()

hl = df2['headline'].values
cat = df2[['AGRICULTURE', 'AUTO', 'BUSINESS', 'CRYPTOCURRENCY', 'WORLD', 'MARKET', 'PHOTOS', 'LEGAL','ECONOMY', 'RETAIL', 'TELECOM', 'POLITICS', 'HEALTHCARE', 'EARNINGS', 'STARTUP', 'REAL ESTATE', 'AVIATION', 'FINANCE','INFORMATION TECHNOLOGY', 'TECHNOLOGY', 'PERSONAL FINANCE', 'VIEWS', 'NEWS', 'ENERGY', 'YOUNG TURKS', 'INDIA', 'ENVIRONMENT', 'HOSPITALITY', 'TRAVEL', 'ENTERTAINMENT']].values

hl_train, hl_test, cat_train, cat_test = train_test_split(hl, cat, test_size=0.2)

cat_test.shape

padded_test.shape

tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(hl_train)
tokenizer.fit_on_texts(hl_test)

sekuens_train = tokenizer.texts_to_sequences(hl_train)
sekuens_test = tokenizer.texts_to_sequences(hl_test)

padded_train = pad_sequences(sekuens_train)
padded_test = pad_sequences(sekuens_test)

class Callback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if(logs.get('accuracy') > 0.90 and logs.get('val_accuracy') > 0.90):
            print("\nReached 90% accuracy")
            self.model.stop_training = True


callbacks = [Callback()]
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

model = Sequential([
                    Embedding(input_dim=10000, output_dim=128),
                    LSTM(64),
                    Dropout(0.5),
                    Dense(64, activation='relu'),
                    Dropout(0.5),
                    Dense(30, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(padded_train, cat_train, epochs=20, validation_data=(padded_test, cat_test), callbacks=[callbacks], verbose=2)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

